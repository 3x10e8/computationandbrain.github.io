---
layout: post
title: "Homework 5"
date:  Wednesday, October 2 2019
---


### Due Tuesday, October 8 at 11:59 pm on Gradescope. 

NOTE: THIS ASSIGNMENT IS NOT FINALIZED


1. Watch the 2 Jeff Lichtman lectures on "Mapping Neural Connections and Their Development" [[part I]](https://www.youtube.com/watch?v=R2US2yVO4us&t=1s) [[part II]](https://www.youtube.com/watch?v=alIu9NeLbZs). Summarize what you find interesting in this lecture. Respond to at least 2 of the following questions (feel free to respond to more):
    1. Why is/isn't connectomics important for neuroscience?
    2. Do you agree with Lichtman's "U of Science?"
    3.
    4.

2. TBD Read ["Random synaptic feedback weights support error backpropagation for deep learning"](https://www.nature.com/articles/ncomms13276.pdf) by Lillicrap et. al. 

3. TBD Skim this paper by Lin, Tegmark and Rolnick [Why Does Deep and Cheap Learning Work So Well?](https://link.springer.com/article/10.1007/s10955-017-1836-5)


4. What are two discussion points/questions that you have? (We will choose some of these to discuss in class)

Submit a (preferably LaTeX formatted) summary (~2 pages) to [Gradescope](https://www.gradescope.com/courses/61715). Please sign up as per the instructions on [Piazza](https://piazza.com/columbia/fall2019/comse6998_004_2019_1topicsincomputerscience). 

Thanks, and enjoy!
