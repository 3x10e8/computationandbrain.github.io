
---
layout: post
title: "Homework 3"
date:  Friday, September 20 2019
---


### Due Tuesday, Sept. 24 at 11:59 pm on Gradescope. 

The purpose of this assignment is to highlight connections between neural networks. This assignment involves >2 hours of video lectures, so be sure to plan accordingly. Please review all the material and summarize what you find interesting. You do not have to answer every "sub-question."

1. Watch [Geoff Hinton's and Yann Lecun's Turing award speeches](https://www.youtube.com/watch?v=VsnQf7exv5I) (They start at ~10:00). Summarize the parts of the talk that you find interesting. Be sure to include *some* of the following questions:

2. Read this review paper [Deep Neural Networks: A New Framework for Modeling Biological Vision and Brain Information Processing](https://www.annualreviews.org/doi/full/10.1146/annurev-vision-082114-035447) (Kriegeskorte 2015). Be sure to include *some* of the following questions:

3. Skim this classic paper "Approximation Capabilities of Multilayer Feedforward Networks" (Hornik 1991) [here](http://www.vision.jhu.edu/teaching/learning/deeplearning18/assets/Hornik-91.pdf). Be sure to include *some* of the following questions:



The following references are optional but encouraged. If you would like to write about these topics instead, please feel free to do so.

* As a reference on CS-style learning theory (touched on in class), see Chapter 20 of [Understanding Machine Learning](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf) (the textbook pdf is available online). Focus on the sections covering the expressive power of neural networks and the sample complexity of neural networks. To review PAC Learning see chapter 3.1 and VC dimension in chapter 6.

* As a reference on CNNs, see the course notes from Stanford [CS231N](http://cs231n.github.io/convolutional-networks/). 
